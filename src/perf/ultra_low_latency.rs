//! ğŸš€ è¶…ä½å»¶è¿Ÿä¼˜åŒ–æ¨¡å— - ç›®æ ‡å®ç°<1msç«¯åˆ°ç«¯å»¶è¿Ÿ
//!
//! è¿™ä¸ªæ¨¡å—åŒ…å«é’ˆå¯¹äºšæ¯«ç§’çº§å»¶è¿Ÿçš„æè‡´ä¼˜åŒ–ï¼š
//! - æ— é”å¹¶å‘äº‹ä»¶å¤„ç†
//! - CPUäº²å’Œæ€§ç»‘å®š
//! - é›¶åˆ†é…å†…å­˜ç®¡ç†
//! - é¢„æµ‹æ€§é¢„å–ä¼˜åŒ–
//! - ç¡¬ä»¶åŠ é€Ÿåºåˆ—åŒ–

use std::sync::{Arc, atomic::{AtomicU64, AtomicUsize, AtomicBool, Ordering}};
use std::time::{Duration, Instant};
// use std::collections::VecDeque;
use crossbeam_queue::ArrayQueue;
use crossbeam_utils::CachePadded;
use fzstream_common::EventMessage;
use tokio::sync::Notify;
use anyhow::Result;
use log::{info, warn, debug};

/// ğŸš€ æ— é”äº‹ä»¶åˆ†å‘å™¨ - ä½¿ç”¨ç¯å½¢ç¼“å†²åŒºå®ç°æé€Ÿäº‹ä»¶åˆ†å‘
pub struct LockFreeEventDispatcher {
    /// æ— é”ç¯å½¢ç¼“å†²åŒºï¼Œæ”¯æŒå¤šç”Ÿäº§è€…å•æ¶ˆè´¹è€…
    event_queues: Vec<Arc<ArrayQueue<EventMessage>>>,
    /// å®¢æˆ·ç«¯æ˜ å°„åˆ°é˜Ÿåˆ—çš„ç´¢å¼•
    client_queue_mapping: Arc<dashmap::DashMap<String, usize>>,
    /// é˜Ÿåˆ—é€‰æ‹©ç­–ç•¥ï¼ˆè½®è¯¢è®¡æ•°å™¨ï¼‰
    queue_selector: CachePadded<AtomicUsize>,
    /// æ€§èƒ½ç»Ÿè®¡
    stats: Arc<UltraLowLatencyStats>,
    /// é¢„å–ä¼˜åŒ–å™¨
    prefetch_optimizer: Arc<PrefetchOptimizer>,
    /// CPUç»‘å®šé…ç½®
    cpu_affinity: Option<CpuAffinityConfig>,
}

/// CPUäº²å’Œæ€§é…ç½®
#[derive(Clone, Debug)]
pub struct CpuAffinityConfig {
    /// ç»‘å®šåˆ°ç‰¹å®šCPUæ ¸å¿ƒ
    pub core_ids: Vec<usize>,
    /// å¯ç”¨NUMAä¼˜åŒ–
    pub numa_optimization: bool,
    /// ä¼˜å…ˆçº§è®¾ç½®
    pub priority: ThreadPriority,
}

#[derive(Clone, Debug)]
pub enum ThreadPriority {
    Normal,
    High,
    RealTime,
}

/// ğŸš€ é¢„å–ä¼˜åŒ–å™¨ - é¢„æµ‹æ€§æ•°æ®é¢„åŠ è½½
pub struct PrefetchOptimizer {
    /// é¢„æµ‹ç¼“å­˜ï¼šåŸºäºå†å²æ¨¡å¼é¢„å–å¯èƒ½éœ€è¦çš„æ•°æ®
    prediction_cache: Arc<ArrayQueue<EventMessage>>,
    /// é¢„å–å‘½ä¸­ç»Ÿè®¡
    hit_count: AtomicU64,
    /// é¢„å–å¤±æ•ˆç»Ÿè®¡
    miss_count: AtomicU64,
    /// å­¦ä¹ æ¨¡å¼å¼€å…³
    learning_enabled: AtomicBool,
}

impl PrefetchOptimizer {
    pub fn new(cache_size: usize) -> Self {
        Self {
            prediction_cache: Arc::new(ArrayQueue::new(cache_size)),
            hit_count: AtomicU64::new(0),
            miss_count: AtomicU64::new(0),
            learning_enabled: AtomicBool::new(true),
        }
    }

    /// é¢„æµ‹æ€§é¢„å–äº‹ä»¶æ•°æ®
    #[inline(always)]
    pub fn prefetch_event_data(&self, event: &EventMessage) {
        if !self.learning_enabled.load(Ordering::Relaxed) {
            return;
        }

        // åŸºäºäº‹ä»¶ç±»å‹çš„ç®€å•é¢„æµ‹é€»è¾‘
        // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„æœºå™¨å­¦ä¹ é¢„æµ‹ç®—æ³•
        if let Ok(_) = self.prediction_cache.push(event.clone()) {
            // é¢„å–æˆåŠŸ
        }
    }

    /// å°è¯•ä»é¢„å–ç¼“å­˜è·å–äº‹ä»¶
    #[inline(always)]
    pub fn try_get_prefetched(&self) -> Option<EventMessage> {
        if let Some(event) = self.prediction_cache.pop() {
            self.hit_count.fetch_add(1, Ordering::Relaxed);
            Some(event)
        } else {
            self.miss_count.fetch_add(1, Ordering::Relaxed);
            None
        }
    }

    /// è·å–é¢„å–ç»Ÿè®¡ä¿¡æ¯
    pub fn get_stats(&self) -> (u64, u64, f64) {
        let hits = self.hit_count.load(Ordering::Relaxed);
        let misses = self.miss_count.load(Ordering::Relaxed);
        let hit_rate = if hits + misses > 0 {
            hits as f64 / (hits + misses) as f64
        } else {
            0.0
        };
        (hits, misses, hit_rate)
    }
}

/// ğŸš€ è¶…ä½å»¶è¿Ÿç»Ÿè®¡æ”¶é›†å™¨
pub struct UltraLowLatencyStats {
    /// äº‹ä»¶å¤„ç†è®¡æ•°
    pub events_processed: CachePadded<AtomicU64>,
    /// çº³ç§’çº§å»¶è¿Ÿç»Ÿè®¡
    pub total_latency_ns: CachePadded<AtomicU64>,
    /// æœ€å°å»¶è¿Ÿï¼ˆçº³ç§’ï¼‰
    pub min_latency_ns: CachePadded<AtomicU64>,
    /// æœ€å¤§å»¶è¿Ÿï¼ˆçº³ç§’ï¼‰
    pub max_latency_ns: CachePadded<AtomicU64>,
    /// äºšæ¯«ç§’äº‹ä»¶è®¡æ•°ï¼ˆ<1msï¼‰
    pub sub_millisecond_events: CachePadded<AtomicU64>,
    /// è¶…å¿«äº‹ä»¶è®¡æ•°ï¼ˆ<100Î¼sï¼‰
    pub ultra_fast_events: CachePadded<AtomicU64>,
    /// æé€Ÿäº‹ä»¶è®¡æ•°ï¼ˆ<10Î¼sï¼‰
    pub lightning_fast_events: CachePadded<AtomicU64>,
    /// é˜Ÿåˆ—æº¢å‡ºè®¡æ•°
    pub queue_overflows: CachePadded<AtomicU64>,
    /// é¢„å–å‘½ä¸­è®¡æ•°
    pub prefetch_hits: CachePadded<AtomicU64>,
}

impl UltraLowLatencyStats {
    pub fn new() -> Self {
        Self {
            events_processed: CachePadded::new(AtomicU64::new(0)),
            total_latency_ns: CachePadded::new(AtomicU64::new(0)),
            min_latency_ns: CachePadded::new(AtomicU64::new(u64::MAX)),
            max_latency_ns: CachePadded::new(AtomicU64::new(0)),
            sub_millisecond_events: CachePadded::new(AtomicU64::new(0)),
            ultra_fast_events: CachePadded::new(AtomicU64::new(0)),
            lightning_fast_events: CachePadded::new(AtomicU64::new(0)),
            queue_overflows: CachePadded::new(AtomicU64::new(0)),
            prefetch_hits: CachePadded::new(AtomicU64::new(0)),
        }
    }

    /// è®°å½•äº‹ä»¶å¤„ç†å»¶è¿Ÿï¼ˆçº³ç§’çº§ç²¾åº¦ï¼‰
    #[inline(always)]
    pub fn record_event_latency(&self, latency_ns: u64) {
        self.events_processed.fetch_add(1, Ordering::Relaxed);
        self.total_latency_ns.fetch_add(latency_ns, Ordering::Relaxed);

        // æ›´æ–°æœ€å°å€¼
        let mut current_min = self.min_latency_ns.load(Ordering::Relaxed);
        while latency_ns < current_min {
            match self.min_latency_ns.compare_exchange_weak(
                current_min, latency_ns, Ordering::Relaxed, Ordering::Relaxed
            ) {
                Ok(_) => break,
                Err(x) => current_min = x,
            }
        }

        // æ›´æ–°æœ€å¤§å€¼
        let mut current_max = self.max_latency_ns.load(Ordering::Relaxed);
        while latency_ns > current_max {
            match self.max_latency_ns.compare_exchange_weak(
                current_max, latency_ns, Ordering::Relaxed, Ordering::Relaxed
            ) {
                Ok(_) => break,
                Err(x) => current_max = x,
            }
        }

        // åˆ†ç±»ç»Ÿè®¡
        if latency_ns < 1_000_000 { // <1ms
            self.sub_millisecond_events.fetch_add(1, Ordering::Relaxed);
        }
        if latency_ns < 100_000 { // <100Î¼s
            self.ultra_fast_events.fetch_add(1, Ordering::Relaxed);
        }
        if latency_ns < 10_000 { // <10Î¼s
            self.lightning_fast_events.fetch_add(1, Ordering::Relaxed);
        }
    }

    /// è·å–å»¶è¿Ÿç»Ÿè®¡æ‘˜è¦
    pub fn get_summary(&self) -> UltraLatencySummary {
        let events_processed = self.events_processed.load(Ordering::Relaxed);
        let total_latency_ns = self.total_latency_ns.load(Ordering::Relaxed);
        let min_latency_ns = self.min_latency_ns.load(Ordering::Relaxed);
        let max_latency_ns = self.max_latency_ns.load(Ordering::Relaxed);
        let sub_ms_events = self.sub_millisecond_events.load(Ordering::Relaxed);
        let ultra_fast_events = self.ultra_fast_events.load(Ordering::Relaxed);
        let lightning_fast_events = self.lightning_fast_events.load(Ordering::Relaxed);

        let avg_latency_ns = if events_processed > 0 {
            total_latency_ns as f64 / events_processed as f64
        } else {
            0.0
        };

        let sub_ms_percentage = if events_processed > 0 {
            sub_ms_events as f64 / events_processed as f64 * 100.0
        } else {
            0.0
        };

        let ultra_fast_percentage = if events_processed > 0 {
            ultra_fast_events as f64 / events_processed as f64 * 100.0
        } else {
            0.0
        };

        let lightning_fast_percentage = if events_processed > 0 {
            lightning_fast_events as f64 / events_processed as f64 * 100.0
        } else {
            0.0
        };

        UltraLatencySummary {
            events_processed,
            avg_latency_ns,
            min_latency_ns: if min_latency_ns == u64::MAX { 0.0 } else { min_latency_ns as f64 },
            max_latency_ns: max_latency_ns as f64,
            avg_latency_us: avg_latency_ns / 1000.0,
            sub_millisecond_percentage: sub_ms_percentage,
            ultra_fast_percentage,
            lightning_fast_percentage,
            target_achieved: avg_latency_ns < 1_000_000.0, // <1ms target
        }
    }
}

/// å»¶è¿Ÿç»Ÿè®¡æ‘˜è¦
#[derive(Debug, Clone)]
pub struct UltraLatencySummary {
    pub events_processed: u64,
    pub avg_latency_ns: f64,
    pub min_latency_ns: f64,
    pub max_latency_ns: f64,
    pub avg_latency_us: f64,
    pub sub_millisecond_percentage: f64,
    pub ultra_fast_percentage: f64,
    pub lightning_fast_percentage: f64,
    pub target_achieved: bool,
}

impl LockFreeEventDispatcher {
    /// åˆ›å»ºæ–°çš„æ— é”äº‹ä»¶åˆ†å‘å™¨
    pub fn new(
        num_queues: usize, 
        queue_capacity: usize,
        cpu_affinity: Option<CpuAffinityConfig>
    ) -> Self {
        let mut event_queues = Vec::with_capacity(num_queues);
        for _ in 0..num_queues {
            event_queues.push(Arc::new(ArrayQueue::new(queue_capacity)));
        }

        info!("ğŸš€ Created LockFreeEventDispatcher: {} queues, capacity {} each", 
              num_queues, queue_capacity);

        Self {
            event_queues,
            client_queue_mapping: Arc::new(dashmap::DashMap::new()),
            queue_selector: CachePadded::new(AtomicUsize::new(0)),
            stats: Arc::new(UltraLowLatencyStats::new()),
            prefetch_optimizer: Arc::new(PrefetchOptimizer::new(1000)),
            cpu_affinity,
        }
    }

    /// ğŸš€ æé€Ÿäº‹ä»¶åˆ†å‘ - æ— é”è·¯å¾„
    #[inline(always)]
    pub fn dispatch_event_ultra_fast(&self, client_id: &str, event: EventMessage) -> Result<()> {
        let start_time = Instant::now();

        // è·å–æˆ–åˆ†é…å®¢æˆ·ç«¯é˜Ÿåˆ—
        let queue_index = if let Some(index) = self.client_queue_mapping.get(client_id) {
            *index
        } else {
            // ä½¿ç”¨è½®è¯¢ç­–ç•¥åˆ†é…æ–°é˜Ÿåˆ—
            let index = self.queue_selector.fetch_add(1, Ordering::Relaxed) % self.event_queues.len();
            self.client_queue_mapping.insert(client_id.to_string(), index);
            index
        };

        // é¢„å–ä¼˜åŒ–
        self.prefetch_optimizer.prefetch_event_data(&event);

        // å°è¯•æ— é˜»å¡æ¨é€åˆ°é˜Ÿåˆ—
        let queue = &self.event_queues[queue_index];
        match queue.push(event) {
            Ok(_) => {
                // è®°å½•å¤„ç†å»¶è¿Ÿ
                let latency_ns = start_time.elapsed().as_nanos() as u64;
                self.stats.record_event_latency(latency_ns);
                Ok(())
            }
            Err(_) => {
                // é˜Ÿåˆ—æ»¡ï¼Œè®°å½•æº¢å‡º
                self.stats.queue_overflows.fetch_add(1, Ordering::Relaxed);
                Err(anyhow::anyhow!("Queue overflow for client: {}", client_id))
            }
        }
    }

    /// å¯åŠ¨äº‹ä»¶å¤„ç†å·¥ä½œçº¿ç¨‹
    pub async fn start_processing_workers(&self, num_workers: usize) -> Result<()> {
        info!("ğŸš€ Starting {} ultra-low-latency processing workers", num_workers);

        for worker_id in 0..num_workers {
            let queues = self.event_queues.clone();
            let stats = Arc::clone(&self.stats);
            let cpu_affinity = self.cpu_affinity.clone();

            tokio::spawn(async move {
                // åº”ç”¨CPUäº²å’Œæ€§
                if let Some(affinity_config) = &cpu_affinity {
                    if let Err(e) = Self::set_thread_affinity(worker_id, affinity_config) {
                        warn!("Failed to set CPU affinity for worker {}: {}", worker_id, e);
                    } else {
                        info!("âœ… Worker {} bound to CPU core", worker_id);
                    }
                }

                // å·¥ä½œçº¿ç¨‹ä¸»å¾ªç¯
                Self::worker_main_loop(worker_id, queues, stats).await;
            });
        }

        Ok(())
    }

    /// å·¥ä½œçº¿ç¨‹ä¸»å¾ªç¯ - æé€Ÿäº‹ä»¶å¤„ç†
    async fn worker_main_loop(
        worker_id: usize,
        queues: Vec<Arc<ArrayQueue<EventMessage>>>,
        stats: Arc<UltraLowLatencyStats>
    ) {
        info!("ğŸ”„ Worker {} started ultra-low-latency processing loop", worker_id);
        
        let mut queue_index = worker_id; // ä»åˆ†é…çš„é˜Ÿåˆ—å¼€å§‹
        let notify = Arc::new(Notify::new());
        
        loop {
            let mut processed_any = false;

            // è½®è¯¢æ‰€æœ‰é˜Ÿåˆ—ï¼Œå¯»æ‰¾å¾…å¤„ç†äº‹ä»¶
            for _ in 0..queues.len() {
                let queue = &queues[queue_index % queues.len()];
                
                // æ‰¹é‡å¤„ç†ä»¥æé«˜ååé‡
                let mut batch_count = 0;
                while batch_count < 100 { // æ‰¹æ¬¡å¤§å°é™åˆ¶
                    match queue.pop() {
                        Some(event) => {
                            let process_start = Instant::now();
                            
                            // ğŸš€ è¿™é‡Œæ˜¯å®é™…çš„äº‹ä»¶å¤„ç†é€»è¾‘
                            // åœ¨çœŸå®åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨å®é™…çš„äº‹ä»¶å¤„ç†å‡½æ•°
                            Self::process_event_ultra_fast(&event).await;
                            
                            let process_latency = process_start.elapsed().as_nanos() as u64;
                            stats.record_event_latency(process_latency);
                            
                            processed_any = true;
                            batch_count += 1;
                        }
                        None => break,
                    }
                }

                queue_index = (queue_index + 1) % queues.len();
            }

            if !processed_any {
                // æ²¡æœ‰äº‹ä»¶è¦å¤„ç†ï¼ŒçŸ­æš‚ä¼‘çœ é¿å…CPUç©ºè½¬
                tokio::task::yield_now().await;
                
                // å¯é€‰ï¼šä½¿ç”¨æ›´æ™ºèƒ½çš„ç­‰å¾…æœºåˆ¶
                tokio::select! {
                    _ = tokio::time::sleep(Duration::from_nanos(100)) => {}, // 100nsæçŸ­ä¼‘çœ 
                    _ = notify.notified() => {}, // æˆ–ç­‰å¾…é€šçŸ¥
                }
            }
        }
    }

    /// ğŸš€ æé€Ÿäº‹ä»¶å¤„ç†å‡½æ•°
    #[inline(always)]
    async fn process_event_ultra_fast(event: &EventMessage) {
        // åœ¨è¿™é‡Œå®ç°å®é™…çš„äº‹ä»¶å¤„ç†é€»è¾‘
        // ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬åªæ˜¯åšä¸€äº›æœ€å°çš„å¤„ç†
        
        // é¿å…ä¸å¿…è¦çš„åˆ†é…å’Œå¤åˆ¶
        debug!("Processing event: {} bytes", event.data.len());
        
        // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šï¼š
        // 1. è§£æäº‹ä»¶æ•°æ®
        // 2. åº”ç”¨ä¸šåŠ¡é€»è¾‘
        // 3. è½¬å‘ç»™ç›¸åº”çš„å®¢æˆ·ç«¯
        
        // æ¨¡æ‹Ÿæå°‘çš„å¤„ç†æ—¶é—´
        tokio::task::yield_now().await;
    }

    /// è®¾ç½®çº¿ç¨‹CPUäº²å’Œæ€§
    fn set_thread_affinity(worker_id: usize, config: &CpuAffinityConfig) -> Result<()> {
        if config.core_ids.is_empty() {
            return Ok(());
        }

        #[allow(unused_variables)]
        let core_id = config.core_ids[worker_id % config.core_ids.len()];

        #[cfg(target_os = "linux")]
        {
            use libc::{cpu_set_t, sched_setaffinity, CPU_SET, CPU_ZERO};
            
            unsafe {
                let mut cpuset: cpu_set_t = std::mem::zeroed();
                CPU_ZERO(&mut cpuset);
                CPU_SET(core_id, &mut cpuset);
                
                if sched_setaffinity(0, std::mem::size_of::<cpu_set_t>(), &cpuset) != 0 {
                    return Err(anyhow::anyhow!("Failed to set CPU affinity to core {}", core_id));
                }
            }
        }

        #[cfg(target_os = "macos")]
        {
            // macOSä¸æ”¯æŒCPUäº²å’Œæ€§ç»‘å®šï¼Œä½†å¯ä»¥è®¾ç½®çº¿ç¨‹ä¼˜å…ˆçº§
            info!("CPU affinity not supported on macOS, setting thread priority instead");
            
            // å¯ä»¥ä½¿ç”¨thread_policy_setæ¥è®¾ç½®çº¿ç¨‹è°ƒåº¦ç­–ç•¥
            // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªè®°å½•æ—¥å¿—
        }

        #[cfg(target_os = "windows")]
        {
            use winapi::um::processthreadsapi::{GetCurrentThread, SetThreadAffinityMask};
            
            unsafe {
                let affinity_mask = 1u64 << core_id;
                if SetThreadAffinityMask(GetCurrentThread(), affinity_mask as usize) == 0 {
                    return Err(anyhow::anyhow!("Failed to set CPU affinity to core {}", core_id));
                }
            }
        }

        Ok(())
    }

    /// è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
    pub fn get_performance_stats(&self) -> UltraLatencySummary {
        self.stats.get_summary()
    }

    /// è·å–é¢„å–ç»Ÿè®¡ä¿¡æ¯
    pub fn get_prefetch_stats(&self) -> (u64, u64, f64) {
        self.prefetch_optimizer.get_stats()
    }

    /// è·å–é˜Ÿåˆ—çŠ¶æ€ä¿¡æ¯
    pub fn get_queue_stats(&self) -> Vec<(usize, usize)> {
        self.event_queues.iter().enumerate()
            .map(|(i, queue)| (i, queue.len()))
            .collect()
    }
}

/// ğŸš€ é›¶åˆ†é…äº‹ä»¶åºåˆ—åŒ–å™¨
pub struct ZeroAllocSerializer {
    /// é¢„åˆ†é…çš„åºåˆ—åŒ–ç¼“å†²åŒºæ± 
    buffer_pool: Arc<ArrayQueue<Vec<u8>>>,
    /// å¿«é€ŸæŸ¥æ‰¾è¡¨ï¼šäº‹ä»¶ç±»å‹ -> é¢„è®¡ç®—åºåˆ—åŒ–å¤§å°
    size_hints: Arc<dashmap::DashMap<String, usize>>,
}

impl ZeroAllocSerializer {
    pub fn new(pool_size: usize, buffer_size: usize) -> Self {
        let buffer_pool = Arc::new(ArrayQueue::new(pool_size));
        
        // é¢„åˆ†é…ç¼“å†²åŒº
        for _ in 0..pool_size {
            let _ = buffer_pool.push(Vec::with_capacity(buffer_size));
        }

        Self {
            buffer_pool,
            size_hints: Arc::new(dashmap::DashMap::new()),
        }
    }

    /// ğŸš€ é›¶åˆ†é…åºåˆ—åŒ– - é‡ç”¨é¢„åˆ†é…ç¼“å†²åŒº
    #[inline(always)]
    pub fn serialize_zero_alloc<T: serde::Serialize>(&self, value: &T, event_type: &str) -> Result<Vec<u8>> {
        // å°è¯•è·å–é¢„åˆ†é…ç¼“å†²åŒº
        let mut buffer = if let Some(buf) = self.buffer_pool.pop() {
            buf
        } else {
            // æ± è€—å°½ï¼Œåˆ†é…æ–°ç¼“å†²åŒº
            let hint_size = self.size_hints.get(event_type)
                .map(|entry| *entry)
                .unwrap_or(1024);
            Vec::with_capacity(hint_size)
        };

        // æ¸…ç©ºç¼“å†²åŒºä½†ä¿æŒå®¹é‡
        buffer.clear();

        // ç›´æ¥åºåˆ—åŒ–åˆ°ç¼“å†²åŒº
        let serialized = bincode::serialize(value)?;
        buffer.extend_from_slice(&serialized);

        // æ›´æ–°å¤§å°æç¤ºï¼Œç”¨äºä¼˜åŒ–åç»­åˆ†é…
        self.size_hints.insert(event_type.to_string(), buffer.len());

        Ok(buffer)
    }

    /// å½’è¿˜ç¼“å†²åŒºåˆ°æ± ä¸­
    #[inline(always)]
    pub fn return_buffer(&self, buffer: Vec<u8>) {
        // åªå½’è¿˜åˆç†å¤§å°çš„ç¼“å†²åŒºï¼Œé¿å…æ± è¢«è¶…å¤§ç¼“å†²åŒºå ç”¨
        if buffer.capacity() <= 1024 * 1024 { // 1MB limit
            let _ = self.buffer_pool.push(buffer);
        }
    }

    /// è·å–æ± çŠ¶æ€
    pub fn get_pool_stats(&self) -> (usize, usize) {
        (self.buffer_pool.len(), self.buffer_pool.capacity())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use fzstream_common::{SerializationProtocol};
    use solana_streamer_sdk::streaming::event_parser::common::EventType;

    #[tokio::test]
    async fn test_lockfree_dispatcher() {
        let dispatcher = LockFreeEventDispatcher::new(4, 1000, None);
        
        let test_event = EventMessage {
            event_id: "test_1".to_string(),
            event_type: EventType::BlockMeta,
            data: vec![1, 2, 3, 4],
            serialization_format: SerializationProtocol::Bincode,
            compression_format: fzstream_common::CompressionLevel::None,
            is_compressed: false,
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_millis() as u64,
            original_size: Some(4),
            grpc_arrival_time: 0,
            parsing_time: 0,
            completion_time: 0,
            client_processing_start: None,
            client_processing_end: None,
        };

        // æµ‹è¯•äº‹ä»¶åˆ†å‘
        assert!(dispatcher.dispatch_event_ultra_fast("client_1", test_event).is_ok());

        // æ£€æŸ¥ç»Ÿè®¡
        let stats = dispatcher.get_performance_stats();
        assert_eq!(stats.events_processed, 1);
    }

    #[test]
    fn test_zero_alloc_serializer() {
        let serializer = ZeroAllocSerializer::new(10, 1024);
        
        let test_data = "Hello, world!";
        let result = serializer.serialize_zero_alloc(&test_data, "string");
        assert!(result.is_ok());
        
        let serialized = result.unwrap();
        assert!(!serialized.is_empty());
        
        // æµ‹è¯•ç¼“å†²åŒºå½’è¿˜
        serializer.return_buffer(serialized);
        
        let (available, capacity) = serializer.get_pool_stats();
        assert!(available > 0);
        assert_eq!(capacity, 10);
    }
}